{"name":"Brain Imaging Pipelines","tagline":"BIPs","body":"# Welcome to Anisha's BIPs Tutorials\r\nThese tutorials will try to explain how to use the BIPS workflows I've written and how you can contribute to BIPs.\r\n\r\nBIPS is a collection of [Nipype](http://nipy.sourceforge.net/nipype/) workflows that can be customized for specific projects with little knowledge of python/programming. Ideally, we hope that BIPs users will learn some programming so they can debug problems and eventually contribute new workflows.\r\n\r\nThe project-specific parameters for each BIPs workflow are saved in a .json file, which you can edit with a text editor of your choice. At the moment, BIPs comes with a user interface where you can edit your .json file. You can open the interface by:\r\n\r\n`\r\n$bips -c <first 2-3 id digits of workflow>\r\n`\r\n\r\nWhere the id is a string of numbers and letters that point to your workflow. To see all workflow id's type:\r\n\r\n`\r\n$bips -l\r\n`\r\n\r\nWhen you run your workfow by typing \r\n\r\n`\r\n$bips -r your_config_file.json\r\n`\r\n\r\nA python script will save in the same location as your config file. This is the Nipype workflow configured for your project. You should save these scripts when you are done with a project, because BIPs workflows may change, but your script stays the same.\r\n \r\n\r\n# fMRI Task Analysis\r\n\r\nA full fMRI task analysis (using SPM or FSL) can be done with BIPs the following workflows:\r\n\r\n1. Convert dicoms using [dcmstack]() or workflow **df4** in BIPs\r\n2. Send your structural image to [recon-all]()\r\n3. Manually correct your reconned images in freesurfer before moving on\r\n4. Normalize your freesurfer structural to a template using workflow **21ab**\r\n5. Preprocess your functional data:\r\n   * **don't** regress any nuisance variables\r\n   * don't bandpass filter if you are using SPM modeling (set highpass and lowpass freq to -1)\r\n   * if using SPM modeling, do not do scaling\r\n6. First Level Modeling with **8ef** for FSL, **02e** for FSL with ev files already generated, **a43** for SPM\r\n7. If using FSL and you have more than 1 run, use workflow **726** for fixed effects\r\n8. Run segstats **2c59** for average contrast values in each individual freesurfer region (or any label file), group the segstats across subjects **31a1**, and run statistics using R (or whatever package you want)  \r\n9. Normalize your con images/copes&varcopes using worklow **3a2e**\r\n10. Run second-level analyses:\r\n   * **f08** for one sample T-test in FSL\r\n   * **51ef** for multiple regression in FSL\r\n   * **2d12** for one sample and/or regression in SPM\r\n\r\nFor example configs are results see my results page for the [SAD Novelty Project](http://web.mit.edu/keshavan/Public/novel)\r\n\r\n# fMRI Resting State Analysis\r\n\r\nA resting state analysis can be run on the surface or the volume. I have not written bips workflows for graph theory metrics yet, but there are toolboxes in python or matlab that can do this.\r\n\r\n1. Convert dicoms using [dcmstack]() or workflow **df4** in BIPs\r\n2. Send your structural image to [recon-all]()\r\n3. Manually correct your reconned images in freesurfer before moving on\r\n4. Normalize your freesurfer structural to a template using workflow **21ab**\r\n5. Preprocess your functional data:\r\n   * **do** regress nuisance variables\r\n   * **do** detrend if using [CompCor]()\r\n6. Map resting timeseries to the surface and create correlation matrices using **2b00**\r\n7. View surface timeseries correlations using **974** using the interactive displays\r\n8. For a volume analysis, create ROIs (subject specific or in normalized space) and run workflow **f5c**. The outputs are: ROI to ROI (in a text file which you can run stats on), and ROI-to-voxel images, where you can run workflows **f08**, **51ef** for FSL, and **2d12** for SPM group level analysis.\r\n\r\n\r\n# Using the Datagrabber\r\nIn order to understand how the datagrabber module works, first read the nipype documentation on the [datagrabber node](http://www.mit.edu/~satra/nipype-nightly/users/grabbing_and_sinking.html). \r\n\r\nI'll try to explain it my own way:\r\n\r\n* **Fields**: you can add or delete fields. Each field has **values**. Always keep the one with the name \"subject_id\"\r\n\r\n  * You can click the \"iterable\" box to run the workflow for each value in the field. This is usually clicked for the \"subject_id\" field, except for group level workflows\r\n\r\n  * Lets say you want to run a workflow for each run separately. Add a field with the name \"run\" and with values: 1,2,3,4,5. Click the iterable box.\r\n\r\n* **Base directory**: The base directory for your data. This will be inserted before each field template\r\n\r\n* **Field template**: The pattern the datagrabber will match to find your files. To insert a **value** from a field, type '%s'. \r\n\r\n* **Template args**: Tells the datagrabber what to substitute the '%s' from the **Field template** \r\n\r\nLets say our **Field template looked like this**:\r\n\r\n`\r\n{\"functional_run\":'%s/func_run_%s.nii'}\r\n`\r\n\r\nTemplate args would be:\r\n\r\n`\r\n{\"functional_run\":[['subject_id','run']]}\r\n`\r\n\r\nWhere subject_id and run are defined in **Fields** as \"subject_01\" and \"1,2,3,4,5\" respectively. The datagrabber will find:\r\n\r\n`\r\n/base/directory/subject_01/func_run_1.nii\r\n/base/directory/subject_01/func_run_2.nii\r\n/base/directory/subject_01/func_run_3.nii\r\n/base/directory/subject_01/func_run_4.nii\r\n/base/directory/subject_01/func_run_5.nii\r\n`\r\n\r\nIf the iterable box is checked for both fields, the workflow will run 5 times. If there were 2 subjects, the workflow would run 10 times.\r\n\r\n# Contributing\r\n\r\nContributing to BIPs requires knowledge of git and nipype. \r\n\r\n[Good nipype tutorial](http://miykael.github.io/nipype-beginner-s-guide/)\r\n\r\n[Git tutorial](http://nbviewer.ipython.org/urls/github.com/fperez/reprosw/raw/master/Version%2520Control.ipynb)\r\n\r\n## Editing and testing\r\n**Fork** the bips repository, **clone** it to your computer, make a **branch** to edit the code. Make sure the setup.py in each folder points to your new directory (if you made one) and each new directory you add as an `__init__.py` file. Each time you make a change, **install** your changes locally by typing \r\n\r\n`\r\npython setup.py install --prefix ~\r\n`\r\n\r\nTo test your changes, make sure your environment variables are set correctly:\r\n\r\n```bash\r\nexport PATH=~/bin:$PATH\r\nexport PYTHONPATH=~/lib/python2.7/site-packages\r\n```\r\n\r\nAnd then test your code in ipython or by typing `bips -c <uuid>`\r\n\r\nFinally, **Push** your branch up to your repository online, and send a **Pull Request** to my repository or the INCF repository.\r\n\r\n## Getting a uuid\r\n\r\nTo get a unique id for your workflow, in ipython type:\r\n\r\n```python\r\nimport uuid\r\nuuid.uuid1().hex\r\n```\r\n\r\n## Useful debugging things\r\n\r\n### Debugging function nodes\r\n\r\n1.Go to the working directory of the function node\r\n\r\n2.In ipython type\r\n\r\n```python\r\nfrom nipype.utils.filemanip import loadpkl\r\ninputs = loadpkl(\"_inputs.pklz\")\r\ninputs.pop(\"function_str\")\r\ninputs.pop(\"ignore_exception\")\r\n```\r\n\r\n3.Import your function from bips:\r\n\r\n```python\r\nfrom bips.workflows.whatever.wherever.yourworkflow import yourfunction\r\n```\r\n\r\n4.Turn on debugger and run function\r\n\r\n```python\r\npdb\r\nyourfunction(**inputs)\r\n```\r\n \r\n5.The debugger will stop inside your function, and you can hopefully figure out where things go wrong. Good luck!","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}